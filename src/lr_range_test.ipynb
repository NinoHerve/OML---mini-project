{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhEMvJ_yNn49","executionInfo":{"status":"ok","timestamp":1713984660206,"user_tz":-120,"elapsed":20682,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"fa3676e3-933a-45e1-99e1-573e6916e31e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnNCkPqBNn4_","executionInfo":{"status":"ok","timestamp":1713985045569,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"4b7fdbde-a727-45ba-87f0-5031a09432e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/cours/MA/MA4 (3)/OptML/project/OML---mini-project-main/src\n"]}],"source":["# cd /content/drive/MyDrive/OML---mini-project/src\n","%cd /content/drive/MyDrive/cours/MA/MA4 (3)/OptML/project/OML---mini-project-main/src"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"d6VZOjmMNn4_","executionInfo":{"status":"ok","timestamp":1713984799459,"user_tz":-120,"elapsed":137107,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"07236f80-e716-4b29-9dc9-7280682e91fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets==2.19.0 (from -r requirements.txt (line 1))\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate==0.4.1 (from -r requirements.txt (line 2))\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.24.1 (from -r requirements.txt (line 3))\n","  Downloading numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0.1)\n","Collecting torch==2.1.0 (from -r requirements.txt (line 5))\n","  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchmetrics==1.3.2 (from -r requirements.txt (line 6))\n","  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.16.0 (from -r requirements.txt (line 7))\n","  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tqdm==4.66.1 (from -r requirements.txt (line 8))\n","  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (3.13.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets==2.19.0->-r requirements.txt (line 1))\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (2.31.0)\n","Collecting xxhash (from datasets==2.19.0->-r requirements.txt (line 1))\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets==2.19.0->-r requirements.txt (line 1))\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets==2.19.0->-r requirements.txt (line 1))\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.0->-r requirements.txt (line 1)) (24.0)\n","Collecting responses<0.19 (from evaluate==0.4.1->-r requirements.txt (line 2))\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 5)) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 5)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 5)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 5)) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting triton==2.1.0 (from torch==2.1.0->-r requirements.txt (line 5))\n","  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lightning-utilities>=0.8.0 (from torchmetrics==1.3.2->-r requirements.txt (line 6))\n","  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0->-r requirements.txt (line 7)) (9.4.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->-r requirements.txt (line 5))\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements.txt (line 1)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements.txt (line 1)) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements.txt (line 1)) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements.txt (line 1)) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.0->-r requirements.txt (line 1)) (4.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.3.2->-r requirements.txt (line 6)) (67.7.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.0->-r requirements.txt (line 1)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.0->-r requirements.txt (line 1)) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.0->-r requirements.txt (line 1)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.0->-r requirements.txt (line 1)) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->-r requirements.txt (line 5)) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->-r requirements.txt (line 1)) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.0->-r requirements.txt (line 1)) (2024.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->-r requirements.txt (line 5)) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.0->-r requirements.txt (line 1)) (1.16.0)\n","Installing collected packages: xxhash, triton, tqdm, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, dill, responses, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, torch, datasets, torchvision, torchmetrics, evaluate\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.2.0\n","    Uninstalling triton-2.2.0:\n","      Successfully uninstalled triton-2.2.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.66.2\n","    Uninstalling tqdm-4.66.2:\n","      Successfully uninstalled tqdm-4.66.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.1+cu121\n","    Uninstalling torch-2.2.1+cu121:\n","      Successfully uninstalled torch-2.2.1+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.17.1+cu121\n","    Uninstalling torchvision-0.17.1+cu121:\n","      Successfully uninstalled torchvision-0.17.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.1 which is incompatible.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\n","torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.19.0 dill-0.3.8 evaluate-0.4.1 huggingface-hub-0.22.2 lightning-utilities-0.11.2 multiprocess-0.70.16 numpy-1.24.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 responses-0.18.0 torch-2.1.0 torchmetrics-1.3.2 torchvision-0.16.0 tqdm-4.66.1 triton-2.1.0 xxhash-3.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"dc2c92a932254929b8257ea80dcb5ada"}},"metadata":{}}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8hzgku5sNn4_","executionInfo":{"status":"ok","timestamp":1713985051633,"user_tz":-120,"elapsed":448,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}}},"outputs":[],"source":["# This cell makes sure modules are auto-loaded when you change external python files\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Jih7wq-XNn4_","executionInfo":{"status":"ok","timestamp":1713985064028,"user_tz":-120,"elapsed":11934,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}}},"outputs":[],"source":["import torch\n","import torch.optim.lr_scheduler as schedulers\n","from utils import retrieve_setup, retrieve_training_params, training_loop"]},{"cell_type":"markdown","source":["## CIFAR exploration"],"metadata":{"id":"QW-EyVU6h7UA"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDZXiVUzNn5A","executionInfo":{"status":"ok","timestamp":1713970360159,"user_tz":-120,"elapsed":728,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"7ca2e59c-c5b9-409d-e321-2dc1d6b79e40"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(0.01, 0.001), (0.01, 0.0001), (0.01, 1e-05), (0.01, 1e-06), (0.001, 0.0001), (0.001, 1e-05), (0.001, 1e-06), (0.0001, 1e-05), (0.0001, 1e-06), (1e-05, 1e-06)]\n"]}],"source":["model_name = \"MobileNetV3Small\"\n","dataset_name = \"CIFAR10\"\n","n_epochs = 8\n","\n","\n","lr_pos = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n","lr_pairs = []\n","\n","for i in range(len(lr_pos)):\n","  for j in range(i+1, len(lr_pos)):\n","    lr_pairs.append((lr_pos[i], lr_pos[j]))\n","\n","print(lr_pairs)"]},{"cell_type":"code","source":["for pair in lr_pairs:\n","  model, dataset = retrieve_setup(model_name, dataset_name)\n","  optimizer, _, loss_fn, _, batch_size = retrieve_training_params(model, dataset_name, \"parameters.yml\")\n","\n","  # change lr from default to lr_max\n","  for g in optimizer.param_groups:\n","      g[\"lr\"] = pair[0]\n","\n","  # implement linear increasing scheduler\n","  total_iters = int(len(dataset[\"train\"])/batch_size*n_epochs)\n","  start_factor = pair[1]/pair[0]\n","\n","  scheduler_name, scheduler = \"rangeLR_pretrained\", schedulers.LinearLR(\n","      optimizer,\n","      start_factor=start_factor,\n","      end_factor=1,\n","      total_iters=total_iters\n","  )\n","\n","  print(f'---training with lr_max={pair[0]} and lr_min={pair[1]}---')\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  _, metrics = training_loop(\n","      model=model,\n","      dataset=dataset,\n","      scheduler=scheduler,\n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      n_epochs=n_epochs,\n","      batch_size=batch_size,\n","      train_strategy=(\"iter\", 25),\n","      test_strategy=(\"iter\", 25),\n","      scheduler_strategy=\"iter\",\n","      file_name=f\"/{dataset_name}_{scheduler_name}_{pair[0]}_{pair[1]}\",\n","      device=device,\n","  )\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsSucrL7ktB2","executionInfo":{"status":"ok","timestamp":1713977374274,"user_tz":-120,"elapsed":89662,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"aad54b96-2eba-46a7-936f-17331c2e8abc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.01 and lr_min=0.001---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.01 and lr_min=0.0001---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.01 and lr_min=1e-05---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.01 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.001 and lr_min=0.0001---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.001 and lr_min=1e-05---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.001 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.0001 and lr_min=1e-05---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=0.0001 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Files already downloaded and verified\n","Files already downloaded and verified\n","---training with lr_max=1e-05 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n"]}]},{"cell_type":"markdown","source":["## FashionMNIST exploration"],"metadata":{"id":"i7foJM92ZAad"}},{"cell_type":"code","source":["model_name = \"MobileNetV3Small\"\n","dataset_name = \"FashionMNIST\"\n","n_epochs = 8\n","\n","\n","lr_pos = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n","lr_pairs = []\n","\n","for i in range(len(lr_pos)):\n","  for j in range(i+1, len(lr_pos)):\n","    lr_pairs.append((lr_pos[i], lr_pos[j]))\n","\n","print(lr_pairs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkStv6aOZEsm","executionInfo":{"status":"ok","timestamp":1713985064028,"user_tz":-120,"elapsed":16,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"5adcced4-0ba1-40bc-f484-d27feb67dd07"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[(0.01, 0.001), (0.01, 0.0001), (0.01, 1e-05), (0.01, 1e-06), (0.001, 0.0001), (0.001, 1e-05), (0.001, 1e-06), (0.0001, 1e-05), (0.0001, 1e-06), (1e-05, 1e-06)]\n"]}]},{"cell_type":"code","source":["for pair in lr_pairs:\n","  model, dataset = retrieve_setup(model_name, dataset_name)\n","  optimizer, _, loss_fn, _, batch_size = retrieve_training_params(model, dataset_name, \"parameters.yml\")\n","\n","  # change lr from default to lr_max\n","  for g in optimizer.param_groups:\n","      g[\"lr\"] = pair[0]\n","\n","  # implement linear increasing scheduler\n","  total_iters = int(len(dataset[\"train\"])/batch_size*n_epochs)\n","  start_factor = pair[1]/pair[0]\n","\n","  scheduler_name, scheduler = \"rangeLR_pretrained\", schedulers.LinearLR(\n","      optimizer,\n","      start_factor=start_factor,\n","      end_factor=1,\n","      total_iters=total_iters\n","  )\n","\n","  print(f'---training with lr_max={pair[0]} and lr_min={pair[1]}---')\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  _, metrics = training_loop(\n","      model=model,\n","      dataset=dataset,\n","      scheduler=scheduler,\n","      optimizer=optimizer,\n","      loss_fn=loss_fn,\n","      n_epochs=n_epochs,\n","      batch_size=batch_size,\n","      train_strategy=(\"iter\", 25),\n","      test_strategy=(\"iter\", 25),\n","      scheduler_strategy=\"iter\",\n","      file_name=f\"/{dataset_name}_{scheduler_name}_{pair[0]}_{pair[1]}\",\n","      device=device,\n","  )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0BprP57Y-0J","executionInfo":{"status":"ok","timestamp":1713994068687,"user_tz":-120,"elapsed":9004673,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"20fdbba8-660a-4e1b-922d-e454b44011b0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["---training with lr_max=0.01 and lr_min=0.001---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.01 and lr_min=0.0001---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.01 and lr_min=1e-05---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.01 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.001 and lr_min=0.0001---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.001 and lr_min=1e-05---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.001 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.0001 and lr_min=1e-05---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=0.0001 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","---training with lr_max=1e-05 and lr_min=1e-06---\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n"]}]},{"cell_type":"markdown","source":["## single lr code"],"metadata":{"id":"gI4VuZO8mObn"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIOtPpe8Nn5A","executionInfo":{"status":"ok","timestamp":1713968189712,"user_tz":-120,"elapsed":14423,"user":{"displayName":"Ambroise Borbély","userId":"06901575923508433137"}},"outputId":"4c0f77e6-8f10-4546-d536-7eac0e8b30bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# retrieves\n","model, dataset = retrieve_setup(model_name, dataset_name)\n","optimizer, _, loss_fn, _, batch_size = retrieve_training_params(model, dataset_name, \"parameters.yml\")\n","\n","# change lr from default to lr_max\n","for g in optimizer.param_groups:\n","    g[\"lr\"] = lr_max\n","\n","# implement linear increasing scheduler\n","total_iters = int(len(dataset[\"train\"])/batch_size*n_epochs)\n","start_factor = lr_min/lr_max\n","\n","scheduler_name, scheduler = \"rangeLR_pretrained\", schedulers.LinearLR(\n","    optimizer,\n","    start_factor=start_factor,\n","    end_factor=1,\n","    total_iters=total_iters\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cWBcc4SxNn5B"},"outputs":[],"source":["# run training loop\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","_, metrics = training_loop(\n","    model=model,\n","    dataset=dataset,\n","    scheduler=scheduler,\n","    optimizer=optimizer,\n","    loss_fn=loss_fn,\n","    n_epochs=n_epochs,\n","    batch_size=batch_size,\n","    train_strategy=(\"iter\", 25),\n","    test_strategy=(\"iter\", 25),\n","    scheduler_strategy=\"iter\",\n","    file_name=f\"/{dataset_name}_{scheduler_name}\",\n","    device=device,\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[],"collapsed_sections":["QW-EyVU6h7UA","gI4VuZO8mObn"],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}